{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accredited-groove",
   "metadata": {},
   "source": [
    "### This CNN uses three conv-pool blocks, with doubling number of filters used per block. Two dense layers at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "similar-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, InputLayer\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "casual-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"conv_pool_batch_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "determined-conditioning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2051 images belonging to 6 classes.\n",
      "Found 225 images belonging to 6 classes.\n",
      "Found 251 images belonging to 6 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "target_size = (175,175)\n",
    "n_training_images = 2051\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  zoom_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  width_shift_range = 0.1,\n",
    "                                  height_shift_range = 0.1,\n",
    "                                  validation_split=0.1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                  validation_split=0.1)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('../data/images/train',\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    subset='training')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory('../data/images/train',\n",
    "                                                       color_mode='rgb',\n",
    "                                                       target_size=target_size,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical',\n",
    "                                                       subset='validation')\n",
    "\n",
    "holdout_generator = test_datagen.flow_from_directory('../data/images/holdout',\n",
    "                                                       color_mode='rgb',\n",
    "                                                       target_size=target_size,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical')\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v, k) for k,v in labels.items())\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fewer-adelaide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_104 (Conv2D)          (None, 175, 175, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 175, 175, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_99 (MaxPooling (None, 87, 87, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 87, 87, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_100 (MaxPoolin (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 43, 43, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_101 (MaxPoolin (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 64)                3612736   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 3,706,502\n",
      "Trainable params: 3,706,438\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=(target_size[0], target_size[1], 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=n_training_images*10//batch_size,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "changed-council",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "65/65 [==============================] - 82s 1s/step - loss: 1.9603 - accuracy: 0.3089 - val_loss: 1.7245 - val_accuracy: 0.2489\n",
      "Epoch 2/1000\n",
      "65/65 [==============================] - 82s 1s/step - loss: 1.4121 - accuracy: 0.4402 - val_loss: 1.6634 - val_accuracy: 0.3244\n",
      "Epoch 3/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 1.3387 - accuracy: 0.4913 - val_loss: 1.6379 - val_accuracy: 0.2711\n",
      "Epoch 4/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 1.2742 - accuracy: 0.5181 - val_loss: 1.5416 - val_accuracy: 0.4311\n",
      "Epoch 5/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 1.2295 - accuracy: 0.5105 - val_loss: 1.4141 - val_accuracy: 0.5022\n",
      "Epoch 6/1000\n",
      "65/65 [==============================] - 88s 1s/step - loss: 1.0712 - accuracy: 0.5871 - val_loss: 1.4123 - val_accuracy: 0.3956\n",
      "Epoch 7/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 1.0421 - accuracy: 0.6006 - val_loss: 1.1623 - val_accuracy: 0.5378\n",
      "Epoch 8/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 1.0166 - accuracy: 0.6256 - val_loss: 1.3438 - val_accuracy: 0.5156\n",
      "Epoch 9/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 1.1308 - accuracy: 0.5690 - val_loss: 1.2270 - val_accuracy: 0.5556\n",
      "Epoch 10/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.9894 - accuracy: 0.6215 - val_loss: 1.5343 - val_accuracy: 0.3733\n",
      "Epoch 11/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.9469 - accuracy: 0.6438 - val_loss: 1.2277 - val_accuracy: 0.5378\n",
      "Epoch 12/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.9815 - accuracy: 0.6310 - val_loss: 1.4005 - val_accuracy: 0.4489\n",
      "Epoch 13/1000\n",
      "65/65 [==============================] - 89s 1s/step - loss: 0.9420 - accuracy: 0.6527 - val_loss: 1.1781 - val_accuracy: 0.5378\n",
      "Epoch 14/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.9689 - accuracy: 0.6755 - val_loss: 1.2679 - val_accuracy: 0.5111\n",
      "Epoch 15/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.9648 - accuracy: 0.6687 - val_loss: 1.0958 - val_accuracy: 0.5244\n",
      "Epoch 16/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.8473 - accuracy: 0.6948 - val_loss: 1.1651 - val_accuracy: 0.5422\n",
      "Epoch 17/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.8935 - accuracy: 0.6610 - val_loss: 1.3577 - val_accuracy: 0.4978\n",
      "Epoch 18/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.8825 - accuracy: 0.6633 - val_loss: 1.3117 - val_accuracy: 0.5022\n",
      "Epoch 19/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.9279 - accuracy: 0.6422 - val_loss: 1.4309 - val_accuracy: 0.4489\n",
      "Epoch 20/1000\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.7593 - accuracy: 0.7281 - val_loss: 1.9970 - val_accuracy: 0.4089\n",
      "Epoch 21/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.7626 - accuracy: 0.7139 - val_loss: 0.9740 - val_accuracy: 0.6489\n",
      "Epoch 22/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.7846 - accuracy: 0.6913 - val_loss: 0.8825 - val_accuracy: 0.6489\n",
      "Epoch 23/1000\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.7791 - accuracy: 0.7115 - val_loss: 1.2708 - val_accuracy: 0.5956\n",
      "Epoch 24/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.7250 - accuracy: 0.7182 - val_loss: 2.6887 - val_accuracy: 0.4000\n",
      "Epoch 25/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.7741 - accuracy: 0.7045 - val_loss: 1.2415 - val_accuracy: 0.5422\n",
      "Epoch 26/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.7542 - accuracy: 0.7198 - val_loss: 0.9168 - val_accuracy: 0.6356\n",
      "Epoch 27/1000\n",
      "65/65 [==============================] - 89s 1s/step - loss: 0.7492 - accuracy: 0.7187 - val_loss: 0.9220 - val_accuracy: 0.6178\n",
      "Epoch 28/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.7627 - accuracy: 0.7200 - val_loss: 1.1861 - val_accuracy: 0.5822\n",
      "Epoch 29/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.7171 - accuracy: 0.7411 - val_loss: 0.9212 - val_accuracy: 0.6622\n",
      "Epoch 30/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.6799 - accuracy: 0.7477 - val_loss: 1.2058 - val_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.7648 - accuracy: 0.7258 - val_loss: 1.7146 - val_accuracy: 0.5600\n",
      "Epoch 32/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.6731 - accuracy: 0.7385 - val_loss: 1.1465 - val_accuracy: 0.5644\n",
      "Epoch 33/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.6414 - accuracy: 0.7648 - val_loss: 1.1835 - val_accuracy: 0.6622\n",
      "Epoch 34/1000\n",
      "65/65 [==============================] - 87s 1s/step - loss: 0.6119 - accuracy: 0.7777 - val_loss: 1.5146 - val_accuracy: 0.5289\n",
      "Epoch 35/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.6397 - accuracy: 0.7562 - val_loss: 0.9069 - val_accuracy: 0.7289\n",
      "Epoch 36/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.6589 - accuracy: 0.7608 - val_loss: 0.9202 - val_accuracy: 0.6711\n",
      "Epoch 37/1000\n",
      "65/65 [==============================] - 87s 1s/step - loss: 0.6001 - accuracy: 0.7870 - val_loss: 0.9747 - val_accuracy: 0.6889\n",
      "Epoch 38/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.6940 - accuracy: 0.7590 - val_loss: 1.0188 - val_accuracy: 0.6800\n",
      "Epoch 39/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.6030 - accuracy: 0.7752 - val_loss: 1.0765 - val_accuracy: 0.6978\n",
      "Epoch 40/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.5931 - accuracy: 0.7839 - val_loss: 1.0183 - val_accuracy: 0.6711\n",
      "Epoch 41/1000\n",
      "65/65 [==============================] - 87s 1s/step - loss: 0.6244 - accuracy: 0.7729 - val_loss: 1.5841 - val_accuracy: 0.5378\n",
      "Epoch 42/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.6055 - accuracy: 0.7761 - val_loss: 0.8650 - val_accuracy: 0.7022\n",
      "Epoch 43/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.5677 - accuracy: 0.7912 - val_loss: 1.1327 - val_accuracy: 0.6800\n",
      "Epoch 44/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.6075 - accuracy: 0.7875 - val_loss: 0.8914 - val_accuracy: 0.6978\n",
      "Epoch 45/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.5396 - accuracy: 0.7932 - val_loss: 0.9541 - val_accuracy: 0.7111\n",
      "Epoch 46/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.5364 - accuracy: 0.8038 - val_loss: 3.3091 - val_accuracy: 0.4267\n",
      "Epoch 47/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.5561 - accuracy: 0.7879 - val_loss: 1.0047 - val_accuracy: 0.6711\n",
      "Epoch 48/1000\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.5243 - accuracy: 0.8123 - val_loss: 2.2502 - val_accuracy: 0.5333\n",
      "Epoch 49/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.5613 - accuracy: 0.7868 - val_loss: 0.9493 - val_accuracy: 0.6756\n",
      "Epoch 50/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.5606 - accuracy: 0.7827 - val_loss: 1.0054 - val_accuracy: 0.6311\n",
      "Epoch 51/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.5129 - accuracy: 0.8098 - val_loss: 2.1272 - val_accuracy: 0.4222\n",
      "Epoch 52/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.7042 - accuracy: 0.7377 - val_loss: 0.8229 - val_accuracy: 0.7111\n",
      "Epoch 53/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.5576 - accuracy: 0.8010 - val_loss: 0.8278 - val_accuracy: 0.7200\n",
      "Epoch 54/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.4698 - accuracy: 0.8296 - val_loss: 0.8860 - val_accuracy: 0.7200\n",
      "Epoch 55/1000\n",
      "65/65 [==============================] - 87s 1s/step - loss: 0.4789 - accuracy: 0.8207 - val_loss: 1.1710 - val_accuracy: 0.6578\n",
      "Epoch 56/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.5342 - accuracy: 0.7997 - val_loss: 0.9680 - val_accuracy: 0.7511\n",
      "Epoch 57/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4856 - accuracy: 0.8124 - val_loss: 1.0057 - val_accuracy: 0.7467\n",
      "Epoch 58/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.6618 - accuracy: 0.7882 - val_loss: 0.9077 - val_accuracy: 0.6756\n",
      "Epoch 59/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.5310 - accuracy: 0.8007 - val_loss: 0.9123 - val_accuracy: 0.7511\n",
      "Epoch 60/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.5225 - accuracy: 0.8088 - val_loss: 0.9184 - val_accuracy: 0.7200\n",
      "Epoch 61/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.4933 - accuracy: 0.8120 - val_loss: 0.7030 - val_accuracy: 0.8133\n",
      "Epoch 62/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.4128 - accuracy: 0.8501 - val_loss: 0.9362 - val_accuracy: 0.7111\n",
      "Epoch 63/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.5252 - accuracy: 0.8100 - val_loss: 0.8921 - val_accuracy: 0.7600\n",
      "Epoch 64/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4590 - accuracy: 0.8339 - val_loss: 2.0856 - val_accuracy: 0.5289\n",
      "Epoch 65/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4326 - accuracy: 0.8463 - val_loss: 0.9585 - val_accuracy: 0.7289\n",
      "Epoch 66/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.4651 - accuracy: 0.8328 - val_loss: 0.8574 - val_accuracy: 0.7200\n",
      "Epoch 67/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4659 - accuracy: 0.8272 - val_loss: 0.9501 - val_accuracy: 0.7022\n",
      "Epoch 68/1000\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.3752 - accuracy: 0.8730 - val_loss: 0.8505 - val_accuracy: 0.7244\n",
      "Epoch 69/1000\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.4082 - accuracy: 0.8517 - val_loss: 1.3669 - val_accuracy: 0.6178\n",
      "Epoch 70/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.3954 - accuracy: 0.8625 - val_loss: 1.9894 - val_accuracy: 0.5156\n",
      "Epoch 71/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4353 - accuracy: 0.8509 - val_loss: 1.0914 - val_accuracy: 0.6844\n",
      "Epoch 72/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4733 - accuracy: 0.8260 - val_loss: 2.3493 - val_accuracy: 0.4756\n",
      "Epoch 73/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.4285 - accuracy: 0.8468 - val_loss: 0.7611 - val_accuracy: 0.7867\n",
      "Epoch 74/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.3844 - accuracy: 0.8736 - val_loss: 2.1356 - val_accuracy: 0.5733\n",
      "Epoch 75/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.4137 - accuracy: 0.8607 - val_loss: 0.8195 - val_accuracy: 0.7689\n",
      "Epoch 76/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.4012 - accuracy: 0.8576 - val_loss: 1.4782 - val_accuracy: 0.5200\n",
      "Epoch 77/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4064 - accuracy: 0.8430 - val_loss: 0.8360 - val_accuracy: 0.7378\n",
      "Epoch 78/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.3797 - accuracy: 0.8744 - val_loss: 1.1764 - val_accuracy: 0.6933\n",
      "Epoch 79/1000\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.4017 - accuracy: 0.8533 - val_loss: 0.8429 - val_accuracy: 0.7511\n",
      "Epoch 80/1000\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.3840 - accuracy: 0.8673 - val_loss: 2.3665 - val_accuracy: 0.4044\n",
      "Epoch 81/1000\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.5652 - accuracy: 0.8030 - val_loss: 1.1808 - val_accuracy: 0.6533\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('conv_pool_batch.h5')\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(get_run_logdir())\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = validation_generator, \n",
    "    verbose=1,\n",
    "    epochs = 1000,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "minus-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout accuracy: 0.8645418286323547\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(holdout_generator, verbose=0)\n",
    "print('Holdout accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-courtesy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
