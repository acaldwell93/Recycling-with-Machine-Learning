{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "endless-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minimal-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"model2_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "vulnerable-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1824 images belonging to 6 classes.\n",
      "Found 452 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "target_size = (128,96)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  validation_split=0.2)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('../data/images/train',\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory('../data/images/train',\n",
    "                                                       color_mode='rgb',\n",
    "                                                       target_size=target_size,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical',\n",
    "                                                       subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mighty-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 6, strides=2, padding='valid', input_shape=[target_size[0],target_size[1],3]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(3,3), strides=2, padding='valid'),\n",
    "    keras.layers.Conv2D(128, 5, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.MaxPooling2D(pool_size=(3,3), strides=2, padding='valid'),\n",
    "    keras.layers.Conv2D(256, 3, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv2D(128, 3, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv2D(64, 3, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(3,3), strides=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "overhead-martin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 59, 43, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 59, 43, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 59, 43, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 29, 21, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 29, 21, 128)       307328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 29, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 29, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 14, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 14, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 14, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 14, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 14, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 14, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 14, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 14, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 14, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 14, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 6, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,198,086\n",
      "Trainable params: 1,196,870\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "mobile-nepal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "57/57 [==============================] - 50s 851ms/step - loss: 2.1274 - accuracy: 0.2463 - val_loss: 1.7936 - val_accuracy: 0.1903\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 50s 878ms/step - loss: 1.5548 - accuracy: 0.3648 - val_loss: 1.7364 - val_accuracy: 0.2367\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 51s 899ms/step - loss: 1.4170 - accuracy: 0.4300 - val_loss: 1.7611 - val_accuracy: 0.2058\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 51s 887ms/step - loss: 1.3600 - accuracy: 0.4518 - val_loss: 1.7452 - val_accuracy: 0.2788\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 54s 953ms/step - loss: 1.3309 - accuracy: 0.4859 - val_loss: 1.7068 - val_accuracy: 0.2854\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 51s 891ms/step - loss: 1.3344 - accuracy: 0.4918 - val_loss: 1.9073 - val_accuracy: 0.2765\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 51s 889ms/step - loss: 1.2406 - accuracy: 0.5186 - val_loss: 1.6339 - val_accuracy: 0.3473\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 51s 898ms/step - loss: 1.2253 - accuracy: 0.5385 - val_loss: 1.8630 - val_accuracy: 0.2942\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 51s 896ms/step - loss: 1.1391 - accuracy: 0.5555 - val_loss: 1.9934 - val_accuracy: 0.2810\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 55s 970ms/step - loss: 1.2018 - accuracy: 0.5377 - val_loss: 2.6521 - val_accuracy: 0.2987\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 52s 902ms/step - loss: 1.2028 - accuracy: 0.5465 - val_loss: 1.8215 - val_accuracy: 0.2743\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 51s 898ms/step - loss: 1.1631 - accuracy: 0.5619 - val_loss: 1.6090 - val_accuracy: 0.3451\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 52s 904ms/step - loss: 1.1721 - accuracy: 0.5719 - val_loss: 3.0435 - val_accuracy: 0.3075\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 52s 905ms/step - loss: 1.1276 - accuracy: 0.5730 - val_loss: 3.2477 - val_accuracy: 0.2522\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 52s 908ms/step - loss: 1.0637 - accuracy: 0.5982 - val_loss: 3.5423 - val_accuracy: 0.2588\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 53s 933ms/step - loss: 1.0681 - accuracy: 0.6167 - val_loss: 2.0564 - val_accuracy: 0.3319\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 53s 933ms/step - loss: 1.0451 - accuracy: 0.6150 - val_loss: 1.9148 - val_accuracy: 0.2942\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 53s 921ms/step - loss: 1.0599 - accuracy: 0.5977 - val_loss: 3.7240 - val_accuracy: 0.2345\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 51s 902ms/step - loss: 0.9595 - accuracy: 0.6404 - val_loss: 2.4520 - val_accuracy: 0.3097\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 52s 907ms/step - loss: 1.0166 - accuracy: 0.6181 - val_loss: 1.8012 - val_accuracy: 0.3783\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 52s 903ms/step - loss: 1.0224 - accuracy: 0.6209 - val_loss: 1.4917 - val_accuracy: 0.4358\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 52s 916ms/step - loss: 0.9096 - accuracy: 0.6552 - val_loss: 3.2858 - val_accuracy: 0.2699\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 51s 900ms/step - loss: 0.9865 - accuracy: 0.6433 - val_loss: 2.6856 - val_accuracy: 0.3695\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 52s 904ms/step - loss: 0.9544 - accuracy: 0.6296 - val_loss: 3.0547 - val_accuracy: 0.2080\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 51s 902ms/step - loss: 0.8646 - accuracy: 0.6650 - val_loss: 4.8060 - val_accuracy: 0.2942\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 54s 946ms/step - loss: 0.9344 - accuracy: 0.6565 - val_loss: 4.2119 - val_accuracy: 0.2389\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 57s 1s/step - loss: 0.8912 - accuracy: 0.6558 - val_loss: 3.1049 - val_accuracy: 0.3252\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 57s 1s/step - loss: 0.9030 - accuracy: 0.6423 - val_loss: 1.7645 - val_accuracy: 0.3916\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 52s 903ms/step - loss: 0.9026 - accuracy: 0.6577 - val_loss: 4.4530 - val_accuracy: 0.2633\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 51s 902ms/step - loss: 0.8555 - accuracy: 0.6799 - val_loss: 1.6709 - val_accuracy: 0.4403\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 52s 909ms/step - loss: 0.8239 - accuracy: 0.6908 - val_loss: 1.7331 - val_accuracy: 0.4314\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('model3.h5')\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(get_run_logdir())\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = validation_generator, \n",
    "    verbose=1,\n",
    "    epochs = 50,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-puzzle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
