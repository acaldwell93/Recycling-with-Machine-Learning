{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sweet-pantyhose",
   "metadata": {},
   "source": [
    "### This CNN uses two conv-conv-pool blocks with 16,16 and 32,32 filters in the convolution layers. Two final dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "double-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, InputLayer\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aerial-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"conv_conv_pool_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "medical-robert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2051 images belonging to 6 classes.\n",
      "Found 225 images belonging to 6 classes.\n",
      "Found 251 images belonging to 6 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "target_size = (175,175)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  zoom_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  width_shift_range = 0.1,\n",
    "                                  height_shift_range = 0.1,\n",
    "                                  validation_split=0.1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                  validation_split=0.1)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('../data/images/train',\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    subset='training')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory('../data/images/train',\n",
    "                                                       color_mode='rgb',\n",
    "                                                       target_size=target_size,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical',\n",
    "                                                       subset='validation')\n",
    "\n",
    "holdout_generator = test_datagen.flow_from_directory('../data/images/holdout',\n",
    "                                                       color_mode='rgb',\n",
    "                                                       target_size=target_size,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical')\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v, k) for k,v in labels.items())\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "damaged-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 175, 175, 16)      2368      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 175, 175, 16)      12560     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 87, 87, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 87, 87, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 87, 87, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 59168)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                3786816   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 3,816,022\n",
      "Trainable params: 3,816,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), padding='same', input_shape=(target_size[0], target_size[1], 3), activation='relu'))\n",
    "model.add(Conv2D(16, (3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "crude-netscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65/65 [==============================] - 80s 1s/step - loss: 1.7032 - accuracy: 0.2565 - val_loss: 1.3917 - val_accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 74s 1s/step - loss: 1.4271 - accuracy: 0.4180 - val_loss: 1.3038 - val_accuracy: 0.4533\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 74s 1s/step - loss: 1.2789 - accuracy: 0.4950 - val_loss: 1.2519 - val_accuracy: 0.4933\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 78s 1s/step - loss: 1.2307 - accuracy: 0.5211 - val_loss: 1.1692 - val_accuracy: 0.5689\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 73s 1s/step - loss: 1.1994 - accuracy: 0.5425 - val_loss: 1.1588 - val_accuracy: 0.4889\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 74s 1s/step - loss: 1.0450 - accuracy: 0.6210 - val_loss: 1.0801 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 74s 1s/step - loss: 1.0506 - accuracy: 0.6073 - val_loss: 1.1167 - val_accuracy: 0.5289\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 74s 1s/step - loss: 1.0190 - accuracy: 0.6163 - val_loss: 1.0381 - val_accuracy: 0.5867\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 77s 1s/step - loss: 0.9364 - accuracy: 0.6380 - val_loss: 1.1533 - val_accuracy: 0.5867\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 74s 1s/step - loss: 0.9168 - accuracy: 0.6619 - val_loss: 1.0435 - val_accuracy: 0.6000\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.8981 - accuracy: 0.6753 - val_loss: 1.0642 - val_accuracy: 0.6133\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.9133 - accuracy: 0.6653 - val_loss: 1.0212 - val_accuracy: 0.5956\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.8654 - accuracy: 0.6802 - val_loss: 0.9485 - val_accuracy: 0.6622\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.7687 - accuracy: 0.7257 - val_loss: 0.8380 - val_accuracy: 0.6578\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.8007 - accuracy: 0.7072 - val_loss: 0.9467 - val_accuracy: 0.6222\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.7844 - accuracy: 0.7081 - val_loss: 0.7858 - val_accuracy: 0.6933\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.7684 - accuracy: 0.7268 - val_loss: 0.9287 - val_accuracy: 0.6844\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 81s 1s/step - loss: 0.7148 - accuracy: 0.7392 - val_loss: 0.9523 - val_accuracy: 0.6711\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 81s 1s/step - loss: 0.6954 - accuracy: 0.7560 - val_loss: 0.8579 - val_accuracy: 0.6933\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 76s 1s/step - loss: 0.7036 - accuracy: 0.7568 - val_loss: 0.8980 - val_accuracy: 0.6978\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 77s 1s/step - loss: 0.7022 - accuracy: 0.7499 - val_loss: 0.9032 - val_accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 77s 1s/step - loss: 0.6505 - accuracy: 0.7626 - val_loss: 0.8779 - val_accuracy: 0.7022\n",
      "Epoch 23/50\n",
      "65/65 [==============================] - 80s 1s/step - loss: 0.8840 - accuracy: 0.6650 - val_loss: 0.8722 - val_accuracy: 0.6800\n",
      "Epoch 24/50\n",
      "65/65 [==============================] - 87s 1s/step - loss: 0.6699 - accuracy: 0.7648 - val_loss: 0.8749 - val_accuracy: 0.6933\n",
      "Epoch 25/50\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.6231 - accuracy: 0.7739 - val_loss: 0.9138 - val_accuracy: 0.6933\n",
      "Epoch 26/50\n",
      "65/65 [==============================] - 78s 1s/step - loss: 0.6313 - accuracy: 0.7738 - val_loss: 0.7404 - val_accuracy: 0.7467\n",
      "Epoch 27/50\n",
      "65/65 [==============================] - 75s 1s/step - loss: 0.5630 - accuracy: 0.7830 - val_loss: 0.8477 - val_accuracy: 0.7422\n",
      "Epoch 28/50\n",
      "65/65 [==============================] - 76s 1s/step - loss: 0.6059 - accuracy: 0.7783 - val_loss: 0.9603 - val_accuracy: 0.6933\n",
      "Epoch 29/50\n",
      "65/65 [==============================] - 75s 1s/step - loss: 0.5742 - accuracy: 0.7980 - val_loss: 1.1675 - val_accuracy: 0.6267\n",
      "Epoch 30/50\n",
      "65/65 [==============================] - 77s 1s/step - loss: 0.7771 - accuracy: 0.7284 - val_loss: 0.8824 - val_accuracy: 0.6711\n",
      "Epoch 31/50\n",
      "65/65 [==============================] - 79s 1s/step - loss: 0.6663 - accuracy: 0.7534 - val_loss: 1.0110 - val_accuracy: 0.6578\n",
      "Epoch 32/50\n",
      "65/65 [==============================] - 80s 1s/step - loss: 0.6008 - accuracy: 0.7767 - val_loss: 0.8143 - val_accuracy: 0.7289\n",
      "Epoch 33/50\n",
      "65/65 [==============================] - 75s 1s/step - loss: 0.6288 - accuracy: 0.7693 - val_loss: 0.9060 - val_accuracy: 0.6933\n",
      "Epoch 34/50\n",
      "65/65 [==============================] - 79s 1s/step - loss: 0.6254 - accuracy: 0.7606 - val_loss: 0.8815 - val_accuracy: 0.6844\n",
      "Epoch 35/50\n",
      "65/65 [==============================] - 78s 1s/step - loss: 0.6893 - accuracy: 0.7466 - val_loss: 0.8634 - val_accuracy: 0.7200\n",
      "Epoch 36/50\n",
      "65/65 [==============================] - 77s 1s/step - loss: 0.5470 - accuracy: 0.7824 - val_loss: 0.8881 - val_accuracy: 0.6933\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"conv_conv_pool.h5\")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(get_run_logdir())\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = validation_generator, \n",
    "    verbose=1,\n",
    "    epochs = 50,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "golden-accommodation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.788844645023346\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(holdout_generator, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "historic-arena",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746666669845581"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-gospel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
